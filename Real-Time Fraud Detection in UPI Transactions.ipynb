{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9ccfa42-1523-4090-9186-c03920560076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded successfully!\n",
      "üîπ Starting real-time UPI fraud detection simulation...\n",
      "üì¢ Transaction 1: Amount=‚Çπ7168.38, Status=‚úÖ Normal\n",
      "üì¢ Transaction 2: Amount=‚Çπ8653.63, Status=‚úÖ Normal\n",
      "üì¢ Transaction 3: Amount=‚Çπ6186.32, Status=‚úÖ Normal\n",
      "üì¢ Transaction 4: Amount=‚Çπ5135.52, Status=‚úÖ Normal\n",
      "üì¢ Transaction 5: Amount=‚Çπ4594.13, Status=‚úÖ Normal\n",
      "\n",
      "üìä Model Performance on Training Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99   6354407\n",
      "           1       0.01      0.04      0.01      8213\n",
      "\n",
      "    accuracy                           0.99   6362620\n",
      "   macro avg       0.50      0.52      0.50   6362620\n",
      "weighted avg       1.00      0.99      0.99   6362620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ensure Faker is installed (Fix for ModuleNotFoundError)\n",
    "try:\n",
    "    from faker import Faker\n",
    "except ModuleNotFoundError:\n",
    "    print(\"‚ö† Faker module is missing. Installing...\")\n",
    "    os.system(\"pip install faker\")\n",
    "    from faker import Faker\n",
    "\n",
    "# Initialize Faker for synthetic data\n",
    "fake = Faker()\n",
    "\n",
    "# Updated dataset path (Your Provided Path)\n",
    "dataset_path = r\"C:\\Users\\hp\\Downloads\\archive (10)\\PS_20174392719_1491204439457_log.csv\"\n",
    "\n",
    "# Verify dataset existence\n",
    "if os.path.exists(dataset_path):\n",
    "    try:\n",
    "        data = pd.read_csv(dataset_path)\n",
    "        print(\"‚úÖ Dataset loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading dataset: {e}\")\n",
    "        data = pd.DataFrame(columns=['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest'])  # Empty fallback DataFrame\n",
    "else:\n",
    "    print(f\"‚ùå File not found: {dataset_path}. Please verify the path.\")\n",
    "    data = pd.DataFrame(columns=['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest'])  # Empty fallback DataFrame\n",
    "\n",
    "# Data preprocessing\n",
    "features = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "X = data[features].fillna(0)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train Isolation Forest model\n",
    "model = IsolationForest(contamination=0.01, random_state=42)\n",
    "model.fit(X_scaled)\n",
    "\n",
    "# Function to generate synthetic UPI transactions\n",
    "def generate_transaction():\n",
    "    return {\n",
    "        'amount': np.random.uniform(10, 10000),\n",
    "        'oldbalanceOrg': np.random.uniform(0, 50000),\n",
    "        'newbalanceOrig': np.random.uniform(0, 50000),\n",
    "        'oldbalanceDest': np.random.uniform(0, 100000),\n",
    "        'newbalanceDest': np.random.uniform(0, 100000)\n",
    "    }\n",
    "\n",
    "# Simulate real-time transaction stream\n",
    "def simulate_realtime_stream(n_transactions=5):\n",
    "    print(\"üîπ Starting real-time UPI fraud detection simulation...\")\n",
    "    for i in range(n_transactions):\n",
    "        transaction = generate_transaction()\n",
    "        transaction_df = pd.DataFrame([transaction])\n",
    "        \n",
    "        # Scale the transaction data\n",
    "        transaction_scaled = scaler.transform(transaction_df)\n",
    "        \n",
    "        # Predict fraud (1: normal, -1: anomaly)\n",
    "        prediction = model.predict(transaction_scaled)\n",
    "        \n",
    "        # Output result\n",
    "        status = \"üö® Fraud\" if prediction[0] == -1 else \"‚úÖ Normal\"\n",
    "        print(f\"üì¢ Transaction {i+1}: Amount=‚Çπ{transaction['amount']:.2f}, Status={status}\")\n",
    "        \n",
    "        # Simulate real-time delay\n",
    "        time.sleep(1)\n",
    "\n",
    "# Run the simulation\n",
    "simulate_realtime_stream(n_transactions=5)\n",
    "\n",
    "# Evaluate model on test data\n",
    "if \"isFraud\" in data.columns:\n",
    "    y_pred = model.predict(X_scaled)\n",
    "    y_pred = [1 if x == -1 else 0 for x in y_pred]  # Convert to 0/1\n",
    "    y_true = data['isFraud']\n",
    "\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(\"\\nüìä Model Performance on Training Data:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "else:\n",
    "    print(\"\\n‚ö† No fraud labels found in dataset. Evaluation skipped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "476f8c20-7cf2-4664-89fa-4c55700f9a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded successfully!\n",
      "üîπ Starting real-time UPI fraud detection simulation...\n",
      "üì¢ Transaction 1: Amount=‚Çπ8455.97, Status=‚úÖ Normal\n",
      "üì¢ Transaction 2: Amount=‚Çπ8134.43, Status=‚úÖ Normal\n",
      "üì¢ Transaction 3: Amount=‚Çπ9124.72, Status=‚úÖ Normal\n",
      "üì¢ Transaction 4: Amount=‚Çπ7106.54, Status=‚úÖ Normal\n",
      "üì¢ Transaction 5: Amount=‚Çπ8406.65, Status=‚úÖ Normal\n",
      "\n",
      "üìä Model Performance on Training Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95   6354407\n",
      "           1       0.42      0.14      0.21    635440\n",
      "\n",
      "    accuracy                           0.90   6989847\n",
      "   macro avg       0.67      0.56      0.58   6989847\n",
      "weighted avg       0.87      0.90      0.88   6989847\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE  # Oversampling for fraud cases\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ensure Faker is installed\n",
    "try:\n",
    "    from faker import Faker\n",
    "except ModuleNotFoundError:\n",
    "    print(\"‚ö† Faker module is missing. Installing...\")\n",
    "    os.system(\"pip install faker\")\n",
    "    from faker import Faker\n",
    "\n",
    "# Initialize Faker for synthetic data\n",
    "fake = Faker()\n",
    "\n",
    "# Updated dataset path (Your Provided Path)\n",
    "dataset_path = r\"C:\\Users\\hp\\Downloads\\archive (10)\\PS_20174392719_1491204439457_log.csv\"\n",
    "\n",
    "# Verify dataset existence\n",
    "if os.path.exists(dataset_path):\n",
    "    try:\n",
    "        data = pd.read_csv(dataset_path)\n",
    "        print(\"‚úÖ Dataset loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading dataset: {e}\")\n",
    "        data = pd.DataFrame(columns=['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest'])  # Empty fallback DataFrame\n",
    "else:\n",
    "    print(f\"‚ùå File not found: {dataset_path}. Please verify the path.\")\n",
    "    data = pd.DataFrame(columns=['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest'])  # Empty fallback DataFrame\n",
    "\n",
    "# Feature Engineering\n",
    "data['transaction_freq'] = data.groupby('nameOrig')['amount'].transform('count')  # Frequency per account\n",
    "data['previous_fraud'] = data.groupby('nameOrig')['isFraud'].transform('sum')  # Previous fraud cases per account\n",
    "\n",
    "# Data preprocessing\n",
    "features = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'transaction_freq', 'previous_fraud']\n",
    "data.fillna(0, inplace=True)\n",
    "X = data[features]\n",
    "y = data['isFraud'] if 'isFraud' in data.columns else pd.Series(np.zeros(X.shape[0]))  # Default to no fraud if missing\n",
    "\n",
    "# Apply SMOTE to balance fraud cases\n",
    "smote = SMOTE(sampling_strategy=0.1, random_state=42)  # Increase fraud samples\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "\n",
    "# Train Optimized Isolation Forest model\n",
    "model = IsolationForest(contamination=0.03, random_state=42)\n",
    "model.fit(X_scaled)\n",
    "\n",
    "# Function to generate synthetic UPI transactions\n",
    "def generate_transaction():\n",
    "    return {\n",
    "        'amount': np.random.uniform(10, 10000),\n",
    "        'oldbalanceOrg': np.random.uniform(0, 50000),\n",
    "        'newbalanceOrig': np.random.uniform(0, 50000),\n",
    "        'oldbalanceDest': np.random.uniform(0, 100000),\n",
    "        'newbalanceDest': np.random.uniform(0, 100000),\n",
    "        'transaction_freq': np.random.randint(1, 100),  # Simulated frequency\n",
    "        'previous_fraud': np.random.randint(0, 10)  # Simulated past fraud cases\n",
    "    }\n",
    "\n",
    "# Simulate real-time transaction stream\n",
    "def simulate_realtime_stream(n_transactions=5):\n",
    "    print(\"üîπ Starting real-time UPI fraud detection simulation...\")\n",
    "    for i in range(n_transactions):\n",
    "        transaction = generate_transaction()\n",
    "        transaction_df = pd.DataFrame([transaction])\n",
    "        \n",
    "        # Scale the transaction data\n",
    "        transaction_scaled = scaler.transform(transaction_df)\n",
    "        \n",
    "        # Predict fraud (1: normal, -1: anomaly)\n",
    "        prediction = model.predict(transaction_scaled)\n",
    "        \n",
    "        # Output result\n",
    "        status = \"üö® Fraud\" if prediction[0] == -1 else \"‚úÖ Normal\"\n",
    "        print(f\"üì¢ Transaction {i+1}: Amount=‚Çπ{transaction['amount']:.2f}, Status={status}\")\n",
    "        \n",
    "        # Simulate real-time delay\n",
    "        time.sleep(1)\n",
    "\n",
    "# Run the simulation\n",
    "simulate_realtime_stream(n_transactions=5)\n",
    "\n",
    "# Evaluate model on test data\n",
    "if \"isFraud\" in data.columns:\n",
    "    y_pred = model.predict(X_scaled)\n",
    "    y_pred = [1 if x == -1 else 0 for x in y_pred]  # Convert to 0/1\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(\"\\nüìä Model Performance on Training Data:\")\n",
    "    print(classification_report(y_resampled, y_pred))\n",
    "else:\n",
    "    print(\"\\n‚ö† No fraud labels found in dataset. Evaluation skipped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d241b3-a145-4815-909c-0c5e73056b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE  # Oversampling for fraud cases\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ensure Faker is installed\n",
    "try:\n",
    "    from faker import Faker\n",
    "except ModuleNotFoundError:\n",
    "    print(\"‚ö† Faker module is missing. Installing...\")\n",
    "    os.system(\"pip install faker\")\n",
    "    from faker import Faker\n",
    "\n",
    "# Initialize Faker for synthetic data\n",
    "fake = Faker()\n",
    "\n",
    "# Updated dataset path (Your Provided Path)\n",
    "dataset_path = r\"C:\\Users\\hp\\Downloads\\archive (10)\\PS_20174392719_1491204439457_log.csv\"\n",
    "\n",
    "# Verify dataset existence\n",
    "if os.path.exists(dataset_path):\n",
    "    try:\n",
    "        data = pd.read_csv(dataset_path)\n",
    "        print(\"‚úÖ Dataset loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading dataset: {e}\")\n",
    "        data = pd.DataFrame(columns=['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest'])  # Empty fallback DataFrame\n",
    "else:\n",
    "    print(f\"‚ùå File not found: {dataset_path}. Please verify the path.\")\n",
    "    data = pd.DataFrame(columns=['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest'])  # Empty fallback DataFrame\n",
    "\n",
    "# Advanced Feature Engineering\n",
    "data['transaction_time'] = pd.to_datetime(data['step'], unit='s')  # Simulated transaction timestamps\n",
    "data['account_age'] = data.groupby('nameOrig')['step'].transform('min')  # Account age based on first transaction\n",
    "data['transaction_network'] = data.groupby('nameOrig')['amount'].transform('sum')  # Total transaction amount per account\n",
    "\n",
    "# Data preprocessing\n",
    "features = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'account_age', 'transaction_network']\n",
    "data.fillna(0, inplace=True)\n",
    "X = data[features]\n",
    "y = data['isFraud'] if 'isFraud' in data.columns else pd.Series(np.zeros(X.shape[0]))  # Default to no fraud if missing\n",
    "\n",
    "# Apply SMOTE to balance fraud cases\n",
    "smote = SMOTE(sampling_strategy=0.1, random_state=42)  # Increase fraud samples\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "\n",
    "# Train Hybrid Fraud Models\n",
    "models = {\n",
    "    \"Isolation Forest\": IsolationForest(contamination=0.05, random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"Autoencoder (Neural Network)\": MLPClassifier(hidden_layer_sizes=(64, 32, 16), max_iter=500)\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nüîπ Training {model_name}...\")\n",
    "    model.fit(X_scaled, y_resampled)\n",
    "\n",
    "# Function to generate synthetic UPI transactions\n",
    "def generate_transaction():\n",
    "    return {\n",
    "        'amount': np.random.uniform(10, 10000),\n",
    "        'oldbalanceOrg': np.random.uniform(0, 50000),\n",
    "        'newbalanceOrig': np.random.uniform(0, 50000),\n",
    "        'oldbalanceDest': np.random.uniform(0, 100000),\n",
    "        'newbalanceDest': np.random.uniform(0, 100000),\n",
    "        'account_age': np.random.uniform(1, 500),\n",
    "        'transaction_network': np.random.uniform(1000, 500000)\n",
    "    }\n",
    "\n",
    "# Simulate real-time transaction stream\n",
    "def simulate_realtime_stream(n_transactions=5):\n",
    "    print(\"üîπ Starting real-time UPI fraud detection simulation...\")\n",
    "    for i in range(n_transactions):\n",
    "        transaction = generate_transaction()\n",
    "        transaction_df = pd.DataFrame([transaction])\n",
    "        \n",
    "        # Scale the transaction data\n",
    "        transaction_scaled = scaler.transform(transaction_df)\n",
    "        \n",
    "        # Predict fraud using multiple models\n",
    "        predictions = {model_name: model.predict(transaction_scaled)[0] for model_name, model in models.items()}\n",
    "        \n",
    "        # Output result\n",
    "        results = {k: \"üö® Fraud\" if v == -1 else \"‚úÖ Normal\" for k, v in predictions.items()}\n",
    "        print(f\"\\nüì¢ Transaction {i+1}: Amount=‚Çπ{transaction['amount']:.2f}\")\n",
    "        for model_name, result in results.items():\n",
    "            print(f\"üîπ {model_name}: {result}\")\n",
    "        \n",
    "        # Simulate real-time delay\n",
    "        time.sleep(1)\n",
    "\n",
    "# Run the simulation\n",
    "simulate_realtime_stream(n_transactions=5)\n",
    "\n",
    "# Evaluate models on test data\n",
    "if \"isFraud\" in data.columns:\n",
    "    for model_name, model in models.items():\n",
    "        y_pred = model.predict(X_scaled)\n",
    "        y_pred = [1 if x == -1 else 0 for x in y_pred]  # Convert to 0/1\n",
    "        \n",
    "        from sklearn.metrics import classification_report\n",
    "        print(f\"\\nüìä {model_name} - Model Performance on Training Data:\")\n",
    "        print(classification_report(y_resampled, y_pred))\n",
    "else:\n",
    "    print(\"\\n‚ö† No fraud labels found in dataset. Evaluation skipped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c744eac3-3c9a-495f-87ca-c53aed4849d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
